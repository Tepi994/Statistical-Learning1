{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using Gradient Descent with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "tf.set_random_seed(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.load(\"proyecto_training_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 6)\n"
     ]
    }
   ],
   "source": [
    "### First 80% of dataset used as training set\n",
    "ds_train = ds[:int(len(ds)*0.8),0:7]\n",
    "print(np.shape(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292, 6)\n"
     ]
    }
   ],
   "source": [
    "## Last 20% of dataset used as test set. \n",
    "ds_test = ds[int(len(ds)*0.8):int(len(ds)),0:7]\n",
    "print(np.shape(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x= ds_train[:,1]\n",
    "x = [9,8,8.5]\n",
    "#y= ds_train[:,0]\n",
    "y =[19,16,16.75]\n",
    "n = len(x) # Number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of Training Data \n",
    "plt.scatter(x, y) \n",
    "plt.xlabel('x') \n",
    "plt.xlabel('y') \n",
    "plt.title(\"Training Data\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##placeholders\n",
    "##constantes y placeholders son nodos. por constantes nos referimos a informacion constante. \n",
    "## un placeholder es un nodo vacio, que toma valor hasta que en la sesion ejecutemos el grafo. \n",
    "X = tf.placeholder(\"float\", name = \"X\") \n",
    "Y = tf.placeholder(\"float\", name = \"Y\")\n",
    "\n",
    "#trainable variables defined randomly\n",
    "#W = tf.Variable(np.random.randn(), name = \"W\") \n",
    "W = tf.Variable(0.0, name = \"W\")\n",
    "#b = tf.Variable(np.random.randn(), name = \"b\")\n",
    "#b = tf.Variable(1240.0, name = \"b\")\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 3\n",
    "\n",
    "# Hypothesis \n",
    "with tf.name_scope(\"Hipotesis\"):\n",
    "    #y_pred = tf.add(tf.multiply(X, W), 0, name = \"Hipotesis_producto_punto\") \n",
    "     y_pred = tf.multiply(X, W) \n",
    "\n",
    "with tf.name_scope(\"Cost_func\"):\n",
    "    #Mean Squared Error Cost Function \n",
    "    cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n) \n",
    "  \n",
    "#Gradient Descent Optimizer \n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) \n",
    "  \n",
    "#Global Variables Initializer \n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.name_scope(\"Disturbance\"):\n",
    "    disturbance = tf.summary.scalar(name = \"Costfunction\", tensor = cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Graph\n",
    "<img src=\"./error_graphs/grafo.png\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 W = 1.4712499\n",
      "Training cost: 11.511806\n",
      "Epoch 2 W = 1.8770697\n",
      "Training cost: 1.0059739\n",
      "Epoch 3 W = 1.9890084\n",
      "Training cost: 0.20664708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Starting the Tensorflow Session \n",
    "with tf.Session() as sess: \n",
    "    \n",
    "      \n",
    "    # Initializing the Variables \n",
    "    #ejecutar los nodos \n",
    "    sess.run(init)\n",
    "   \n",
    "   \n",
    "    writer = tf.summary.FileWriter( './linear_regression_graphs/lr_0.0001', sess.graph)\n",
    "    \n",
    "      \n",
    "    # Iterating through all the epochs \n",
    "    for epoch in range(training_epochs): \n",
    "          \n",
    "        # Feeding each data point into the optimizer using Feed Dictionary \n",
    "\n",
    "        sess.run(optimizer, feed_dict = {X : x, Y : y}) \n",
    "          \n",
    "        # Displaying the result after every 50 epochs \n",
    "        if (epoch + 1) % 1 == 0: \n",
    "            # Calculating the cost a every epoch \n",
    "            #c = sess.run(disturbance, feed_dict = {X : x, Y : y}) \n",
    "            training_cost = sess.run(cost, feed_dict ={X: x, Y: y})\n",
    "            \n",
    "            writer.add_summary(c,epoch)\n",
    "            print(\"Epoch\", (epoch + 1),\"W =\", sess.run(W)) \n",
    "            print(\"Training cost:\",training_cost)\n",
    "            #print(c) \n",
    "    \n",
    "    writer.close()\n",
    "    # Storing necessary values to be used outside the Session \n",
    "    #training_cost = sess.run(cost, feed_dict ={X: x, Y: y}) \n",
    "    #weight = sess.run(W) \n",
    "    #bias = sess.run(b) \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " Calculating the predictions \n",
    "predictions = weight * x + bias \n",
    "print(\"Training cost =\", training_cost, \"Weight =\", weight, \"bias =\", bias, '\\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Results \n",
    "#plt.plot(x, y, 'ro', label ='Original data') \n",
    "#plt.plot(x, predictions, label ='Fitted line') \n",
    "#plt.title('Linear Regression Result') \n",
    "#plt.legend() \n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function using a LR of 10\n",
    "<img src=\"./error_graphs/lr_10.PNG\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function using a LR of 1\n",
    "<img src=\"./error_graphs/lr_1.PNG\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function using a LR of 0.1\n",
    "<img src=\"./error_graphs/lr_0.1.PNG\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function using a LR of 0.01\n",
    "<img src=\"./error_graphs/lr_0.01.PNG\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function using a LR of 0.001\n",
    "<img src=\"./error_graphs/lr_.001.PNG\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function using a LR of 0.0001\n",
    "<img src=\"./error_graphs/lr_0.0001.PNG\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "A linear regression model using gradient descent was implemented using 1000 epochs and different learning rates.\n",
    "Using learning rates of 10, 1 and 0.1 didn't show positive results, as error oscilated and did not converged to a certain value.\n",
    "\n",
    "At a learning rate of 0.01 we can see error started to decrease almost linearly down to a value of 1.24e+9\n",
    "At a learning rate of 0.001 and 0.0001 error converged to values near of 1.4e+9 and 2e+9\n",
    "\n",
    "We can see that a the model with a learning rate of 0.01 minimized the error. This is surprising, as I was expecting a better model with a smaller learning rate. However, error did not converged as fast as it was decreased.\n",
    "\n",
    "The model with the learning rate of 0.01 is the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
