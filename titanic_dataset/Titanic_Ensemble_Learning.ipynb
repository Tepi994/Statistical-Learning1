{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name   Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  22.0   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       "2            3                             Heikkinen, Miss. Laina  26.0   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       "4            5                           Allen, Mr. William Henry  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
       "1      1      0          PC 17599  71.2833   C85        C           Upper   \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
       "3      1      0            113803  53.1000  C123        S           Upper   \n",
       "4      0      0            373450   8.0500   NaN        S           Lower   \n",
       "\n",
       "  passenger_sex passenger_survived  \n",
       "0             M                  N  \n",
       "1             F                  Y  \n",
       "2             F                  Y  \n",
       "3             F                  Y  \n",
       "4             M                  N  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_titanic_proyecto.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId             int64\n",
       "Name                   object\n",
       "Age                   float64\n",
       "SibSp                   int64\n",
       "Parch                   int64\n",
       "Ticket                 object\n",
       "Fare                  float64\n",
       "Cabin                  object\n",
       "Embarked               object\n",
       "passenger_class        object\n",
       "passenger_sex          object\n",
       "passenger_survived     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Frequency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode variables to numbers for statistical learning model implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will check if the dataset contains missing values. If some numeric column contains missing values, they will be replaced with mean imputation of the column.\n",
    "\n",
    "Numerical variables will be scaled using *min max normalization* under the hypothesis that this will help models to converge more quickly and to solve for better coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId             0\n",
       "Name                    0\n",
       "Age                   177\n",
       "SibSp                   0\n",
       "Parch                   0\n",
       "Ticket                  0\n",
       "Fare                    0\n",
       "Cabin                 687\n",
       "Embarked                2\n",
       "passenger_class         0\n",
       "passenger_sex           0\n",
       "passenger_survived      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputations for missing values variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *Cabin* will be dropped as it is not used in the model. \n",
    "\n",
    "Mean of *Age* is imputed in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =data.drop(columns=['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].mean()\n",
    "#data['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].fillna((df['Age'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0\n",
       "Name                  0\n",
       "Age                   0\n",
       "SibSp                 0\n",
       "Parch                 0\n",
       "Ticket                0\n",
       "Fare                  0\n",
       "Embarked              2\n",
       "passenger_class       0\n",
       "passenger_sex         0\n",
       "passenger_survived    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#Creating the label encoder\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "#Converting string labels into numbers\n",
    "df['Embarked_encoded'] = encoder.fit_transform(np.array(df['Embarked']))\n",
    "df['class_encoded'] = encoder.fit_transform(np.array(df['passenger_class']))\n",
    "df['sex_encoded'] = encoder.fit_transform(np.array(df['passenger_sex']))\n",
    "df['passenger_survived_encoded'] = encoder.fit_transform(np.array(df['passenger_survived']))\n",
    "#df['fare'] = preprocessing.normalize(np.array(df['Fare']).reshape(1,-1))\n",
    "df['Age'] = preprocessing.normalize(np.array(df['Age']).reshape(1, -1))[0]\n",
    "df['Fare'] = preprocessing.normalize(np.array(df['Fare']).reshape(1, -1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>class_encoded</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.039382</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.026945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.036273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>0.030115</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.036273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name       Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  0.022800   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.039382   \n",
       "2            3                             Heikkinen, Miss. Laina  0.026945   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.036273   \n",
       "4            5                           Allen, Mr. William Henry  0.036273   \n",
       "\n",
       "   SibSp  Parch            Ticket      Fare Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171  0.004112        S           Lower   \n",
       "1      1      0          PC 17599  0.040427        C           Upper   \n",
       "2      0      0  STON/O2. 3101282  0.004495        S           Lower   \n",
       "3      1      0            113803  0.030115        S           Upper   \n",
       "4      0      0            373450  0.004565        S           Lower   \n",
       "\n",
       "  passenger_sex passenger_survived  Embarked_encoded  class_encoded  \\\n",
       "0             M                  N                 2              0   \n",
       "1             F                  Y                 0              2   \n",
       "2             F                  Y                 2              0   \n",
       "3             F                  Y                 2              2   \n",
       "4             M                  N                 2              0   \n",
       "\n",
       "   sex_encoded  passenger_survived_encoded  \n",
       "0            1                           0  \n",
       "1            0                           1  \n",
       "2            0                           1  \n",
       "3            0                           1  \n",
       "4            1                           0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name   Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  22.0   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       "2            3                             Heikkinen, Miss. Laina  26.0   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       "4            5                           Allen, Mr. William Henry  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
       "1      1      0          PC 17599  71.2833   C85        C           Upper   \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
       "3      1      0            113803  53.1000  C123        S           Upper   \n",
       "4      0      0            373450   8.0500   NaN        S           Lower   \n",
       "\n",
       "  passenger_sex passenger_survived  \n",
       "0             M                  N  \n",
       "1             F                  Y  \n",
       "2             F                  Y  \n",
       "3             F                  Y  \n",
       "4             M                  N  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>class_encoded</th>\n",
       "      <th>sex_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039382</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp  Parch      Fare  Embarked_encoded  class_encoded  \\\n",
       "0  0.022800      1      0  0.004112                 2              0   \n",
       "1  0.039382      1      0  0.040427                 0              2   \n",
       "2  0.026945      0      0  0.004495                 2              0   \n",
       "3  0.036273      1      0  0.030115                 2              2   \n",
       "4  0.036273      0      0  0.004565                 2              0   \n",
       "\n",
       "   sex_encoded  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['passenger_survived_encoded']\n",
    "labels.head()\n",
    "df_features = df[['Age','SibSp','Parch','Fare','Embarked_encoded','class_encoded','sex_encoded']]\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_validation, y_train, y_test_validation = train_test_split(df_features, labels,\n",
    "                                                    stratify=labels, \n",
    "                                                    test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test_validation, y_test_validation,\n",
    "                                                    stratify=y_test_validation, \n",
    "                                                    test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (533, 7)  Validation dataset: (178, 7) Test dataset: (178, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:\", X_train.shape,\" Validation dataset:\",X_validation.shape, \"Test dataset:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            passenger_survived_encoded\n",
       "passenger_survived_encoded                            \n",
       "0                                                  329\n",
       "1                                                  204"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).groupby('passenger_survived_encoded').agg({'passenger_survived_encoded':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            passenger_survived_encoded\n",
       "passenger_survived_encoded                            \n",
       "0                                                  110\n",
       "1                                                   68"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_validation).groupby('passenger_survived_encoded').agg({'passenger_survived_encoded':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_survived_encoded</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            passenger_survived_encoded\n",
       "passenger_survived_encoded                            \n",
       "0                                                  110\n",
       "1                                                   68"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).groupby('passenger_survived_encoded').agg({'passenger_survived_encoded':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Logbook for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronicle = pd.DataFrame(columns=[\"Model\",\"Accuracy\",\"Recall\",\"Precision\",\"F1_Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models\n",
    "\n",
    "Models will be trained and then stored so they can be called in ensemble learning model. Each model training will have a description that states which variables where used in the training and a run declaring the number of that type of model trained. \n",
    "\n",
    "Models will be selected as weak learners for the ensemble learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age' 'SibSp' 'Parch' 'Fare' 'Embarked_encoded' 'class_encoded'\n",
      " 'sex_encoded']\n"
     ]
    }
   ],
   "source": [
    "train_bayes = pd.concat([X_train,y_train ], axis=1)\n",
    "train_bayes = train_bayes[['sex_encoded','Embarked_encoded','passenger_survived_encoded']]\n",
    "#train_bayes.columns = ['sex','']\n",
    "\n",
    "#X_train[['sex_encoded','Embarked_encoded']].head()\n",
    "print(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x_train,y_train,x_test,y_test,threshold):\n",
    "    \n",
    "    data =  pd.concat([x_train,y_train ], axis=1)\n",
    "    l = data.drop('passenger_survived_encoded', axis = 1).values.T.tolist()\n",
    "    key = pd.DataFrame(list(product(*l)), \n",
    "                       columns=data.columns[0:len(data.columns)-1])\n",
    "    key = key.drop_duplicates()\n",
    "    key = key.sort_values(by = data.columns[0])\n",
    "    origin_len = len(key.columns)\n",
    "    \n",
    "    for i in range(0, origin_len):\n",
    "        p = pd.DataFrame(np.array(data.groupby(key.columns[i]).size()/len(data)))\n",
    "        p.reset_index(level = None, inplace = True)\n",
    "        p.columns = [key.columns[i], 'p_'+key.columns[i]]\n",
    "        key = pd.merge(key, p, how = 'left')\n",
    "\n",
    "        ct = pd.crosstab(data['passenger_survived_encoded'], data[key.columns[i]]).apply(lambda r: r/r.sum(), axis=1).T\n",
    "        ct.reset_index(level = None, inplace = True)\n",
    "        ct.columns = [key.columns[i], 'pc_'+key.columns[i]+'_0', 'pc_'+key.columns[i]+'_1']\n",
    "        key = pd.merge(key, ct, how = 'left')\n",
    "\n",
    "    key['p_survived_0'] = np.array(data.groupby('passenger_survived_encoded').size()/len(data))[0]\n",
    "    key['p_survived_1'] = np.array(data.groupby('passenger_survived_encoded').size()/len(data))[1]\n",
    "    \n",
    "    prob_0 = 1\n",
    "    prob_1 = 1\n",
    "    for i in range(0, origin_len):\n",
    "        prob_0 *= ((key['pc_'+str(key.columns[i])+'_0']*key['p_survived_0'])/key['p_'+str(key.columns[i])])\n",
    "        prob_1 *= ((key['pc_'+str(key.columns[i])+'_1']*key['p_survived_1'])/key['p_'+str(key.columns[i])])\n",
    "\n",
    "    key['p_0'] = prob_0/(prob_0+prob_1)\n",
    "    key['p_1'] = prob_1/(prob_0+prob_1)\n",
    "    \n",
    "  \n",
    "    pred = pd.merge(x_test, key, how = 'left')\n",
    "    pred_train = pd.merge(data, key, how = 'left')\n",
    "    pred['survived_code_pred'] = np.where(pred['p_1'] > threshold, 1, 0)\n",
    "    pred_train['survived_code_pred'] = np.where(pred_train['p_1'] > threshold, 1, 0)\n",
    "    pred = np.array(pred['survived_code_pred'])\n",
    "    pred_train = np.array(pred_train['survived_code_pred'])\n",
    "    accuracy = accuracy_score(pred,y_test)\n",
    "    accuracy_train = accuracy_score(pred_train,y_train)\n",
    "    print(\"Validation Accuracy: \",accuracy)\n",
    "    print(\"Training Accuracy: \",accuracy_train)\n",
    "    \n",
    "    \n",
    "    #y_pred = decision_tree.predict(x_test)\n",
    "    #accuracy = accuracy_score(y_pred,y_test)\n",
    "    error = 1 - accuracy\n",
    "    recall = recall_score(pred,y_test)\n",
    "    precision = precision_score(pred, y_test)\n",
    "    f1_sc = f1_score(pred,y_test)\n",
    "\n",
    "    dic = dict()\n",
    "    dic['Model']='naive_bayes'\n",
    "    dic['Accuracy']=accuracy\n",
    "    dic['Recall']= recall\n",
    "    dic['Precision']=precision\n",
    "    dic['F1_Score']=f1_sc\n",
    "    description = \"variables:\"+ str(data.columns.values)+ \"_accuracy_\"+str(accuracy)+\"_threshold_\"+str(threshold)+\".pkl\"\n",
    "    dic['Description'] = description\n",
    "\n",
    "   \n",
    "    \n",
    "    #joblib.dump(description)\n",
    "    #return(dic)\n",
    "    \n",
    "    \n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8370786516853933\n",
      "Training Accuracy:  0.7598499061913696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes = naive_bayes(X_train[['sex_encoded','Embarked_encoded']],\n",
    "                    y_train,\n",
    "                    X_validation[['sex_encoded','Embarked_encoded']],\n",
    "                    y_validation,\n",
    "                    threshold=0.5)\n",
    "bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes Model will be saved as a .py file and will be called in the ensemble learning part of the project. This decision has been made as Naive Bayes does not have any hyperparameters to tune, as the procedure is the same for all posible inputs. Only inputs vary, so might as well define a function that can be trained for any combination of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_model(x_train,y_train,x_test,y_test, run,crit=\"entropy\"):\n",
    "    model=\"decision_tree_\"+str(run)\n",
    "    decision_tree = DecisionTreeClassifier(criterion=crit)\n",
    "    decision_tree.fit(x_train,y_train)\n",
    "\n",
    "    y_pred = decision_tree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_pred,y_test)\n",
    "    error = 1 - accuracy\n",
    "    recall = recall_score(y_pred,y_test)\n",
    "    precision = precision_score(y_pred, y_test)\n",
    "    f1_sc = f1_score(y_pred,y_test)\n",
    "\n",
    "    dic = dict()\n",
    "    dic['Model']=model\n",
    "    dic['Accuracy']=accuracy\n",
    "    dic['Recall']= recall\n",
    "    dic['Precision']=precision\n",
    "    dic['F1_Score']=f1_sc\n",
    "    description = \"criterion_\"+ str(crit)+ \"_accuracy_\"+str(accuracy)+\".pkl\"\n",
    "    dic['Description'] = description\n",
    "\n",
    "   \n",
    "    \n",
    "    joblib.dump(decision_tree, description)\n",
    "    return(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': 'decision_tree_2',\n",
       " 'Accuracy': 0.8146067415730337,\n",
       " 'Recall': 0.7966101694915254,\n",
       " 'Precision': 0.6911764705882353,\n",
       " 'F1_Score': 0.7401574803149606,\n",
       " 'Description': 'criterion_entropy_accuracy_0.8146067415730337.pkl'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = decision_tree_model(X_train,y_train,X_validation,y_validation, run=2)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree_1</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>criterion_entropy_accuracy_0.8426966292134831.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_1</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>C_0.5_gamma_1_kernel_rbf.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree_1</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>criterion_entropy_accuracy_0.8202247191011236.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree_2</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>criterion_entropy_accuracy_0.8146067415730337.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy    Recall  Precision  F1_Score  \\\n",
       "0  decision_tree_1  0.842697  0.812500   0.764706  0.787879   \n",
       "1            svm_1  0.859551  0.890909   0.720588  0.796748   \n",
       "2  decision_tree_1  0.820225  0.800000   0.705882  0.750000   \n",
       "3  decision_tree_2  0.814607  0.796610   0.691176  0.740157   \n",
       "\n",
       "                                         Description  \n",
       "0  criterion_entropy_accuracy_0.8426966292134831.pkl  \n",
       "1                       C_0.5_gamma_1_kernel_rbf.pkl  \n",
       "2  criterion_entropy_accuracy_0.8202247191011236.pkl  \n",
       "3  criterion_entropy_accuracy_0.8146067415730337.pkl  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chronicle = chronicle.append(dtm,ignore_index=True)\n",
    "chronicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree_test = joblib.load(\"test.pkl\")\n",
    "#tree_test.predict(X_validation)\n",
    "\n",
    "joblib.load(np.array(chronicle[chronicle['Model']=='decision_tree_1']['Description'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(x_train,y_train,x_test,y_test,run):\n",
    "    model=\"svm_\"+str(run)\n",
    "    svm = SVC()\n",
    "    \n",
    "    \n",
    "    #svm.fit(x_train, y_train)\n",
    "    parameters = {'kernel':('linear', 'rbf'), \n",
    "                  'C':(1,0.25,0.5,0.75),\n",
    "                  'gamma': (1,2,3,'auto'),\n",
    "                  'decision_function_shape':('ovo','ovr'),\n",
    "                  'shrinking':(True,False)}\n",
    "\n",
    "    grid = GridSearchCV(svm, parameters)\n",
    "    grid.fit(x_train,y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = grid.predict(x_test)\n",
    "    accuracy = accuracy_score(y_pred,y_test)\n",
    "    error = 1 - accuracy\n",
    "    recall = recall_score(y_pred,y_test)\n",
    "    precision = precision_score(y_pred, y_test)\n",
    "    f1_sc = f1_score(y_pred,y_test)\n",
    "    \n",
    "    dic = dict()\n",
    "    dic['Model']=model\n",
    "    dic['Accuracy']=accuracy\n",
    "    dic['Recall']= recall\n",
    "    dic['Precision']=precision\n",
    "    dic['F1_Score']=f1_sc\n",
    "    description = \"C_\"+str(grid.best_params_['C'])+ \"_gamma_\"+str(grid.best_params_['gamma'])+\"_kernel_\"+str(grid.best_params_['kernel'])+\".pkl\"\n",
    "    dic['Description'] = description\n",
    "    joblib.dump(grid,description)\n",
    "    \n",
    "    print(description)\n",
    "    print(dic)\n",
    "    return(dic)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jctep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0.5_gamma_1_kernel_rbf.pkl\n",
      "{'Model': 'svm_2', 'Accuracy': 0.8595505617977528, 'Recall': 0.8909090909090909, 'Precision': 0.7205882352941176, 'F1_Score': 0.7967479674796749, 'Description': 'C_0.5_gamma_1_kernel_rbf.pkl'}\n"
     ]
    }
   ],
   "source": [
    "svm = svm_model(X_train,y_train,X_validation,y_validation, run=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree_1</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>criterion_entropy_accuracy_0.8426966292134831.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_1</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>C_0.5_gamma_1_kernel_rbf.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy    Recall  Precision  F1_Score  \\\n",
       "0  decision_tree_1  0.842697  0.812500   0.764706  0.787879   \n",
       "1            svm_1  0.859551  0.890909   0.720588  0.796748   \n",
       "\n",
       "                                         Description  \n",
       "0  criterion_entropy_accuracy_0.8426966292134831.pkl  \n",
       "1                       C_0.5_gamma_1_kernel_rbf.pkl  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chronicle = chronicle.append(svm,ignore_index=True)\n",
    "chronicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt= y_train.values.reshape((y_train.size, 1))\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_model_encoded = pd.DataFrame(y_train)\n",
    "train_labels_model_hot= pd.get_dummies(y_train)\n",
    "train_labels_model = train_labels_model_hot\n",
    "np.shape(train_labels_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_model(epoch_num,lr,batch_size,x_training,y_training, x_validation, y_validation,beta) :\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ###one hot encoding ###\n",
    "    y_training_encoded = pd.DataFrame(y_training)\n",
    "    y_training_hot= pd.get_dummies(y_training)\n",
    "    y_training = y_training_hot\n",
    "    \n",
    "   # y_validation = y_validation.values.reshape(y_validation.size,1)\n",
    "    y_validation_encoded = pd.DataFrame(y_validation)\n",
    "    y_validation_hot = pd.get_dummies(y_validation)\n",
    "    y_validation = y_validation_hot\n",
    "    \n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    ##Hyperparameters\n",
    "    batch = batch_size\n",
    "    #y_training = y_training.values.reshape((y_training.size,1))\n",
    "    m = np.shape(x_training)[1]\n",
    "    n = np.shape(y_training)[1]\n",
    "    training_epochs = epoch_num\n",
    "    learning_rate = lr\n",
    "\n",
    "    x_train = tf.placeholder(tf.float64, shape =[None,m], name=\"x_train\")\n",
    "    y_train = tf.placeholder(tf.float64, shape=[None,n], name=\"y_train\")\n",
    "\n",
    "    #W = tf.Variable(np.random.randn(m,n), name = \"W\") \n",
    "    #b = tf.Variable(np.random.randn(n), name = \"b\")\n",
    "\n",
    "    W = tf.Variable(np.zeros([m,n]), name = \"W\") \n",
    "    b = tf.Variable(np.zeros(n), name = \"b\")\n",
    "\n",
    "    with tf.name_scope(\"Hypotesis\"):\n",
    "        logits = tf.matmul(x_train,W) + b\n",
    "        y_pred = tf.nn.softmax(logits, name=\"Softmax\")\n",
    "\n",
    "    with tf.name_scope(\"Cross_Entropy\"):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_train * tf.log(y_pred), reduction_indices=[1]))\n",
    "        #cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_training, labels=y_training))\n",
    "    \n",
    "    with tf.name_scope(\"Regularization\"):\n",
    "        regularizer = tf.nn.l2_loss(W)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy + beta*regularizer)\n",
    "        \n",
    "        \n",
    "    with tf.name_scope(\"Optimizer\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope(\"Accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_train,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.name_scope(\"Disturbance\"):\n",
    "        disturbance = tf.summary.scalar(name = \"Costfunction\", tensor = cross_entropy)\n",
    "        \n",
    "    with tf.name_scope(\"Accuracy\"):\n",
    "        ac = tf.summary.scalar(name = \"Costfunction\", tensor = accuracy)\n",
    "        \n",
    "    #summaries = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(training_epochs+1):\n",
    "\n",
    "            batch_num = (epoch * batch ) % (len(x_training) -batch)\n",
    "\n",
    "\n",
    "            sess.run(optimizer, feed_dict = {x_train: x_training[batch_num:(batch_num+batch)], \n",
    "                                             y_train : y_training[batch_num:(batch_num+batch)]})\n",
    "\n",
    "\n",
    "\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                c = sess.run(disturbance, feed_dict = {x_train: x_training[batch_num:(batch_num+batch)], \n",
    "                                             y_train : y_training[batch_num:(batch_num+batch)]})\n",
    "                \n",
    "                a = sess.run(ac, feed_dict = {x_train: x_training[batch_num:(batch_num+batch)], \n",
    "                                             y_train : y_training[batch_num:(batch_num+batch)]})\n",
    "                print(\"Epoch: \" +str(epoch))\n",
    "                \n",
    "                print(\"train accuracy: \" + \n",
    "                  str(sess.run(accuracy, feed_dict = {x_train: x_training[batch_num:(batch_num+batch)],\n",
    "                                                      y_train : y_training[batch_num:(batch_num+batch)]})))\n",
    "                \n",
    "                #print(\"validation accuracy: \" + \n",
    "                 # str(sess.run(accuracy, feed_dict = {x_train: x_validation,\n",
    "                  #                                    y_train : y_validation})))\n",
    "                \n",
    "                print(\"\")\n",
    "                \n",
    "                \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "               # writer.add_summary(c,epoch)\n",
    "                #writer.add_summary(a,epoch)\n",
    "                \n",
    "        #weights = W.eval()\n",
    "        #bias = b.eval()\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "            description = \"epochs_\"+str(epoch_num)+ \"_batch_\"+str(batch)+\"_lr_\"+str(lr)+\"_beta_\"+str(beta)+\".pkl\"\n",
    "\n",
    "        \n",
    "            coefficients = (W.eval(),b.eval())\n",
    "        \n",
    "            pickle_out = open(description, 'wb')\n",
    "            pickle.dump(coefficients, pickle_out)\n",
    "            pickle_out.close()\n",
    "        \n",
    "\n",
    "        \n",
    "        return((W.eval(),b.eval()))\n",
    "        \n",
    "        sess.close()\n",
    "        #writer.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99\n",
      "train accuracy: 0.65625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 199\n",
      "train accuracy: 0.65625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 299\n",
      "train accuracy: 0.71875\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 399\n",
      "train accuracy: 0.65625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 499\n",
      "train accuracy: 0.75\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 599\n",
      "train accuracy: 0.6875\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 699\n",
      "train accuracy: 0.40625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 799\n",
      "train accuracy: 0.625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 899\n",
      "train accuracy: 0.625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 999\n",
      "train accuracy: 0.6875\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 1099\n",
      "train accuracy: 0.5625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 1199\n",
      "train accuracy: 0.625\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 1299\n",
      "train accuracy: 0.6875\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 1399\n",
      "train accuracy: 0.75\n",
      "validation accuracy: 0.66292137\n",
      "\n",
      "Epoch: 1499\n",
      "train accuracy: 0.5625\n",
      "validation accuracy: 0.66292137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = multinomial_model(epoch_num=1500, lr=0.01, batch_size=32, x_training=X_train, y_training=y_train,x_validation=X_validation,\n",
    "                  y_validation=y_validation,beta = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00835892, -0.00835892],\n",
       "        [ 0.06978582, -0.06978582],\n",
       "        [-0.06297449,  0.06297449],\n",
       "        [-0.01187224,  0.01187224],\n",
       "        [ 0.09361684, -0.09361684],\n",
       "        [-0.37452618,  0.37452618],\n",
       "        [ 0.6956248 , -0.6956248 ]]), array([-0.04447041,  0.04447041]))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"epochs_1299_batch_32_lr_0.01_beta_0.01.pkl\",\"rb\")\n",
    "log_model = pickle.load(pickle_in)\n",
    "log_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble  Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree_1</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>criterion_entropy_accuracy_0.8426966292134831.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_1</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>C_0.5_gamma_1_kernel_rbf.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree_1</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>criterion_entropy_accuracy_0.8202247191011236.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree_2</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>criterion_entropy_accuracy_0.8146067415730337.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy    Recall  Precision  F1_Score  \\\n",
       "0  decision_tree_1  0.842697  0.812500   0.764706  0.787879   \n",
       "1            svm_1  0.859551  0.890909   0.720588  0.796748   \n",
       "2  decision_tree_1  0.820225  0.800000   0.705882  0.750000   \n",
       "3  decision_tree_2  0.814607  0.796610   0.691176  0.740157   \n",
       "\n",
       "                                         Description  \n",
       "0  criterion_entropy_accuracy_0.8426966292134831.pkl  \n",
       "1                       C_0.5_gamma_1_kernel_rbf.pkl  \n",
       "2  criterion_entropy_accuracy_0.8202247191011236.pkl  \n",
       "3  criterion_entropy_accuracy_0.8146067415730337.pkl  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chronicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading models from joblib dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree =joblib.load(np.array(chronicle[chronicle['Model']=='decision_tree_1']['Description'])[0])\n",
    "support_vector_m = joblib.load(np.array(chronicle[chronicle['Model']=='svm_1']['Description'])[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Naive Bayes from .py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8370786516853933\n",
      "Training Accuracy:  0.7598499061913696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Naive_Bayes as NB\n",
    "\n",
    "bayes = NB.naive_bayes(X_train[['sex_encoded','Embarked_encoded']],\n",
    "                    y_train,\n",
    "                    X_validation[['sex_encoded','Embarked_encoded']],\n",
    "                    y_validation,\n",
    "                    threshold=0.5)\n",
    "bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "support_vector_m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"epochs_1299_batch_32_lr_0.01_beta_0.01.pkl\",\"rb\")\n",
    "log_model = pickle.load(pickle_in)\n",
    "logits = np.matmul(X_test.values,log_model[0]) + log_model[1]\n",
    "y_pred = tf.nn.softmax(logits, name=\"Softmax\")\n",
    "y_pred\n",
    "with tf.Session() as sess:\n",
    "        result = np.where(y_pred.eval()[:,0] <= 0.5, 1,0)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(x_test,y_test):\n",
    "    ##Support Vector Machine\n",
    "    svm_pred = support_vector_m.predict(x_test)\n",
    "    \n",
    "    ##Logistic Model using tensorflow\n",
    "    \n",
    "    pickle_in = open(\"epochs_1299_batch_32_lr_0.01_beta_0.01.pkl\",\"rb\")\n",
    "    log_model = pickle.load(pickle_in)\n",
    "    \n",
    "    logits = np.matmul(X_test.values,log_model[0]) + log_model[1]\n",
    "    logit_pred = tf.nn.softmax(logits, name=\"Softmax\")\n",
    "    logit_pred\n",
    "    with tf.Session() as sess:\n",
    "        logistic_model_pred = np.where(logit_pred.eval()[:,0] <= 0.5, 1,0)\n",
    "        \n",
    "    \n",
    "    bayes = NB.naive_bayes(X_train[['sex_encoded','Embarked_encoded']],\n",
    "                    y_train,\n",
    "                    x_test[['sex_encoded','Embarked_encoded']],\n",
    "                    y_test,\n",
    "                    threshold=0.5)\n",
    "    \n",
    "    dt_pred = decision_tree.predict(x_test)\n",
    "    \n",
    "    predictions =  pd.DataFrame()\n",
    "    predictions['SVM'] = svm_pred\n",
    "    predictions['Logistic_Model'] = logistic_model_pred\n",
    "    predictions['Naive_Bayes'] = bayes\n",
    "    predictions['Decision_Tree'] = dt_pred\n",
    "    predictions['Combined_predictions']= np.array(predictions.mode(axis=1).iloc[:,0])\n",
    "    predictions['Y_test'] = np.array(y_test)\n",
    "    accuracy = accuracy_score(predictions['Y_test'],predictions['Combined_predictions'])\n",
    "    print(\"\")\n",
    "    print(\"Combined Accuracy:\", accuracy)\n",
    "\n",
    "    \n",
    "    return(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8146067415730337\n",
      "Training Accuracy:  0.7598499061913696\n",
      "\n",
      "Combined Accuracy: 0.8033707865168539\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Logistic_Model</th>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <th>Decision_Tree</th>\n",
       "      <th>Combined_predictions</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVM  Logistic_Model  Naive_Bayes  Decision_Tree  Combined_predictions  \\\n",
       "0    1               0            0              0                   0.0   \n",
       "1    1               1            1              1                   1.0   \n",
       "2    0               0            0              0                   0.0   \n",
       "3    0               0            0              0                   0.0   \n",
       "4    0               0            0              1                   0.0   \n",
       "\n",
       "   Y_test  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model(x_test=X_test,y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments and Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "Feature engineering was crucial for model training. Scaling numeric variables **Age** and **Fare** using ***min max normalization*** impacted in a positive way the training accuracy. This could be do to the fact that when applying L2 regularization, this coefficients are not as strongly penalized as when they are not normalized.\n",
    "\n",
    "Imputations for the **Age** variable also affected the accuracy of the models. Mean imputation resulted in a slightly higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Logistic Regression Model\n",
    "Training the logistic regression makes necesarry to apply ***One Hot Encoding*** because a ***SoftMax*** function is being used as a cost function. This is done in order to have a more generalizable model for future predictions of different datasets. In order to perform a prediction, it is necessary to apply the softmax function to the results of the matmul in order to obtain probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Support Vector Machine Model \n",
    "\n",
    "Applying a gridsearch to the SVM training resulted in the optimal accuracy model. Otherwise, getting such value would have required a huge amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Naive Bayes Model \n",
    "\n",
    "Naive Bayes was the most difficult model to develop. Code is not optimal as performance is severely affected after passing more than three variables. However, the model is fairly easy to train because there is no need to tune hyperparameters to obtain decent results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarding Data: Sampling and Training \n",
    "\n",
    "Comparing the accuracy results of the models to other Data Scientist models, we noticed that sampling had an effect in performance. A way to control for this is to apply **knn folds** to the data. This technique ensures that all data is used in the training process and in the validation process. This way you can analyze if the accuracy of your model is close to the average of all the folds or it was obtained just for pure luck.\n",
    "\n",
    "Another approach could be applying **bootstrapping**. When data is scarce, bootstrapping allows to create different samples from the same distribution, to perform several models. Furthermore, if data is unbalanced, bootstrapping allows to undersample or to oversample observations to have a a better train model. This could be used in this dataset if a lesser amount of people would have survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
